We will be extensively using Tensorflow and Keras to heat and train our machine learning model.  { requirements : min 8 core, 16GB RAM, GPU Preferred} If not, you may see 
dealys in training the model.

ACTIVATION FUNCTIONS: Sigmoid, Tanh, ReLU, LeakyReLU, MaxOut and ELU
We wiil choose above activation functions to fire a neuron based on the data. 
Ex: Signmoid is used to predict probability as an output 
Ex: Tanh is used for classification between two classes
Ex: ReLU is most commonly used activation function in CNN's


Loss Functions: It is also referred to as Cost function or error function
Defination: It qunatifies the error between output of the algorithma and given target value


